pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringdist", "ggplot2", "tidyr", "MASS", "reshape2", "plyr", "ggpubr", "qwraps2",
"margins", "texreg", "Zelig", "data.table", "ggcorrplot", "gridExtra",
"stm"), pkgTest)
# set seed
set.seed(12345)
# function for shared legend in ggplot
g_legend <- function(a.gplot){
tmp <- ggplot_gtable(ggplot_build(a.gplot))
leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
legend <- tmp$grobs[[leg]]
return(legend)}
#############
### Load data
#############
# load survey data
kaneData <- read.csv("data/kaneReplication/Trump_News_Experiment.csv", stringsAsFactors = F)
# listwise deletion by variables from survey used in analysis
kaneData$cosineDist <- ifelse(is.na(kaneData$cosineDist), 1, kaneData$cosineDist)
#kaneDataCompleteCases <- kaneData[complete.cases(kaneData),]
##############################
### base models w/ all obs
##############################
kaneData <- within(kaneData, NewsStoryConditions <- relevel(as.factor(NewsStoryConditions), ref = "Control"))
kaneData <- within(kaneData, ideologyFactor3 <- relevel(as.factor(ideologyFactor3), ref = "Independent"))
# compare respondents that receive treatment vs. control
# appears to be positive increase from just receiving non-religious material
baseLM <- zelig(SelectTrump ~ NewsStoryConditions*ideologyFactor3, data=kaneData, model="logit")
#tripIntLM1 <- zelig(SelectTrump ~ NewsStoryConditions*polint*ideologyFactor3, data=kaneData, model="logit")
#tripIntLM2 <- zelig(SelectTrump ~ NewsStoryConditions*ideology*ideologyFactor3, data=kaneData, model="logit")
#controlsLM1 <- zelig(SelectTrump ~ age + race + bornUS + educ +
#                  income + gender + empstat + NewsStoryConditions*polint*ideologyFactor3, data=kaneData, model="logit")
#controlsLM2 <- zelig(SelectTrump ~ age + race + bornUS + educ +
#                       income + gender + empstat + NewsStoryConditions*polint*ideologyFactor3, data=kaneData, model="logit")
texreg(list(baseLM),# tripIntLM1, tripIntLM2),#, controlsLM1),
digits = 3, stars = c(0.01, 0.05, 0.1))
##############################
### re-weighting
##############################
kaneData$avgDist <- 1-((kaneData$cosineDist*.5) + (kaneData$jaccardDist*.5))^4
#cor(1-((kaneData$cosineDist*.5) + (kaneData$jaccardDist*.5))^4, kaneData$correct)
#kaneData$normalizedavgDist <- (kaneData$avgDist - mean(kaneData$avgDist))
#0.1187  0.7116  0.9111  0.8245  0.9790  1.0000
# appears to be positive increase from just receiving non-religious material
baseLMweights <- zelig(SelectTrump ~ NewsStoryConditions*ideologyFactor3, data=kaneData, model="logit", weights="avgDist")
#tripIntLM1weights <- zelig(SelectTrump ~ NewsStoryConditions*polint*ideologyFactor3, data=kaneData, model="logit", weights=kaneData$avgDist)
#tripIntLM2weights <- zelig(SelectTrump ~ NewsStoryConditions*ideology*ideologyFactor3, data=kaneData, model="logit", weights=kaneData$avgDist)
texreg(list(baseLM, baseLMweights), digits = 3, stars = c(0.01, 0.05, 0.1))
#####################################
### removing inattentive participants
#####################################
kaneDataDistanceSubset <- kaneData[kaneData$avgDist>.1,]
kaneDataCorrectSubset <- kaneData[kaneData$correct==1,]
baseLMDistanceSubset <- zelig(SelectTrump ~ NewsStoryConditions*ideologyFactor3, data=kaneDataDistanceSubset, model="logit")
baseLMCorrectSubset <- zelig(SelectTrump ~ NewsStoryConditions*ideologyFactor3, data=kaneDataCorrectSubset, model="logit")
texreg(list(baseLM, baseLMweights, baseLMDistanceSubset, baseLMCorrectSubset),digits = 3, stars = c(0.01, 0.05, 0.1))
#######################
#############################
### marginal effect plot setup
##############################
generateAttentionMarginalEffect <- function(model=NULL, name=NULL, subset=NULL){
if(is.null(model) | is.null(name)){
stop('Please insert a model and tell me what we should call that model!')
}
if(!any(grepl(subset, c("weighted", "full", "listwise", "correct")))){
stop('Please tell me how the data is subsetted! Your options:\n"weighted", "full", "correct", or "listwise"')
}
else{
if(" polint " %in% unlist(strsplit(as.character(model$formula), "*", fixed = T))){
outputMat <- NULL
a10 <-  setx(model, NewsStoryConditions="Control", ideologyFactor3="Republican", polint = i)
a11 <-  setx(model, NewsStoryConditions="Alienate", ideologyFactor3="Republican", polint = i)
a12 <-  setx(model, NewsStoryConditions="Appease", ideologyFactor3="Republican", polint = i)
a20 <-  setx(model, NewsStoryConditions="Control", ideologyFactor3="Independent", polint = i)
a21 <-  setx(model, NewsStoryConditions="Alienate", ideologyFactor3="Independent", polint = i)
a22 <-  setx(model, NewsStoryConditions="Appease", ideologyFactor3="Independent", polint = i)
a30 <-  setx(model, NewsStoryConditions="Control", ideologyFactor3="Democrat", polint = i)
a31 <-  setx(model, NewsStoryConditions="Alienate", ideologyFactor3="Democrat", polint = i)
a32 <-  setx(model, NewsStoryConditions="Appease", ideologyFactor3="Democrat", polint = i)
ss11 <- sim(model, x = a10, x1 = a11, num = 10000)
ss12 <- sim(model, x = a10, x1 = a12, num = 10000)
ss13 <- sim(model, x = a11, x1 = a12, num = 10000)
ss21 <- sim(model, x = a20, x1 = a21, num = 10000)
ss22 <- sim(model, x = a20, x1 = a22, num = 10000)
ss23 <- sim(model, x = a21, x1 = a22, num = 10000)
ss31 <- sim(model, x = a30, x1 = a31, num = 10000)
ss32 <- sim(model, x = a30, x1 = a32, num = 10000)
ss33 <- sim(model, x = a31, x1 = a32, num = 10000)
fd <- cbind(unlist(ss11$sim.out[["x1"]][["fd"]]),
unlist(ss12$sim.out[["x1"]][["fd"]]),
unlist(ss13$sim.out[["x1"]][["fd"]]),
unlist(ss21$sim.out[["x1"]][["fd"]]),
unlist(ss22$sim.out[["x1"]][["fd"]]),
unlist(ss23$sim.out[["x1"]][["fd"]]),
unlist(ss31$sim.out[["x1"]][["fd"]]),
unlist(ss32$sim.out[["x1"]][["fd"]]),
unlist(ss33$sim.out[["x1"]][["fd"]])
)
colnames(fd) <- c("Republican (Control-Alienate)", "Republican (Control-Appease)", "Republican (Alienate-Appease)",
"Independent (Control-Alienate)", "Independent (Control-Appease)", "Independent (Alienate-Appease)",
"Democrat (Control-Alienate)", "Democrat (Control-Appease)", "Democrat (Alienate-Appease)")
r <- data.table(polint = i, firstDiff= fd)
outputMat <- rbind(outputMat, r)
}
else{
for (i in unique(kaneData$polint)) {
outputMat <- NULL
a10 <-  setx(model, NewsStoryConditions="Control", ideologyFactor3="Republican")
a11 <-  setx(model, NewsStoryConditions="Alienate", ideologyFactor3="Republican")
a12 <-  setx(model, NewsStoryConditions="Appease", ideologyFactor3="Republican")
a20 <-  setx(model, NewsStoryConditions="Control", ideologyFactor3="Independent")
a21 <-  setx(model, NewsStoryConditions="Alienate", ideologyFactor3="Independent")
a22 <-  setx(model, NewsStoryConditions="Appease", ideologyFactor3="Independent")
a30 <-  setx(model, NewsStoryConditions="Control", ideologyFactor3="Democrat")
a31 <-  setx(model, NewsStoryConditions="Alienate", ideologyFactor3="Democrat")
a32 <-  setx(model, NewsStoryConditions="Appease", ideologyFactor3="Democrat")
ss11 <- sim(model, x = a10, x1 = a11, num = 10000)
ss12 <- sim(model, x = a10, x1 = a12, num = 10000)
ss13 <- sim(model, x = a11, x1 = a12, num = 10000)
ss21 <- sim(model, x = a20, x1 = a21, num = 10000)
ss22 <- sim(model, x = a20, x1 = a22, num = 10000)
ss23 <- sim(model, x = a21, x1 = a22, num = 10000)
ss31 <- sim(model, x = a30, x1 = a31, num = 10000)
ss32 <- sim(model, x = a30, x1 = a32, num = 10000)
ss33 <- sim(model, x = a31, x1 = a32, num = 10000)
fd <- cbind(unlist(ss11$sim.out[["x1"]][["fd"]]),
unlist(ss12$sim.out[["x1"]][["fd"]]),
unlist(ss13$sim.out[["x1"]][["fd"]]),
unlist(ss21$sim.out[["x1"]][["fd"]]),
unlist(ss22$sim.out[["x1"]][["fd"]]),
unlist(ss23$sim.out[["x1"]][["fd"]]),
unlist(ss31$sim.out[["x1"]][["fd"]]),
unlist(ss32$sim.out[["x1"]][["fd"]]),
unlist(ss33$sim.out[["x1"]][["fd"]])
)
colnames(fd) <- c("Republican (Control-Alienate)", "Republican (Control-Appease)", "Republican (Alienate-Appease)",
"Independent (Control-Alienate)", "Independent (Control-Appease)", "Independent (Alienate-Appease)",
"Democrat (Control-Alienate)", "Democrat (Control-Appease)", "Democrat (Alienate-Appease)")
r <- data.table(firstDiff= fd)
outputMat <- rbind(outputMat, r)
}
outputMat$model <- name; outputMat$subset <- subset
return(outputMat)
}
}
}
firstDiffPlotData <- NULL
firstDiffPlotData <- rbind(generateAttentionMarginalEffect(model=baseLM, name="Select Trump Story", subset="full"),
generateAttentionMarginalEffect(model=baseLMweights, name="Select Trump Story", subset="weighted"),
generateAttentionMarginalEffect(model=baseLMDistanceSubset, name="Select Trump Story", subset="listwise"),
generateAttentionMarginalEffect(model=baseLMCorrectSubset, name="Select Trump Story", subset="correct")
)
firstDiffMeltedData <- melt(firstDiffPlotData, id = c("model", "subset"))
firstDiffMeltedData$variable <- revalue(firstDiffMeltedData$variable, c("firstDiff.Republican (Control-Alienate)"="Republican (Control-Disunited)",
"firstDiff.Republican (Control-Appease)"="Republican (Control-United)",
"firstDiff.Republican (Alienate-Appease)"="Republican (Disunited-United)",
"firstDiff.Independent (Control-Alienate)"="Independent (Control-Disunited)",
"firstDiff.Independent (Control-Appease)"="Independent (Control-United)",
"firstDiff.Independent (Alienate-Appease)"="Independent (Disunited-United)",
"firstDiff.Democrat (Control-Alienate)"="Democrat (Control-Disunited)",
"firstDiff.Democrat (Control-Appease)"="Democrat (Control-United)",
"firstDiff.Democrat (Alienate-Appease)"="Democrat (Disunited-United)")
)
firstDiffMeltedData$subset <- revalue(firstDiffMeltedData$subset, c("full"="Full (OLS)",
"listwise"="Participants w>0.1\n(List-wise deletion OLS)", "weighted"="Full (WLS)",
"correct"="Factually correct\n(List-wise deletion OLS)"))
firstDiffQuartilesPlotData <- cbind(ddply(firstDiffMeltedData, .(variable, model, subset), summarize, FDmean = mean(value)),
FDlow90 = ddply(firstDiffMeltedData, .(variable, model, subset), summarize, FDlow = quantile(value, .05))[,4],
FDhigh90 = ddply(firstDiffMeltedData, .(variable, model, subset), summarize, FDhigh = quantile(value, .95))[,4],
FDlow95 = ddply(firstDiffMeltedData, .(variable, model, subset), summarize, FDlow = quantile(value, .025))[,4],
FDhigh95 = ddply(firstDiffMeltedData, .(variable, model, subset), summarize, FDhigh = quantile(value, .975))[,4]
)
firstDiffQuartilesPlotData$model <- ifelse(grepl("Republican", firstDiffQuartilesPlotData$variable), "Republican",
ifelse(grepl("Independent", firstDiffQuartilesPlotData$variable), "Independent", "Democrat"))
firstDiffQuartilesPlotData$variable <- gsub("\\).*","", firstDiffQuartilesPlotData$variable)
firstDiffQuartilesPlotData$variable <- gsub(".*\\(","", firstDiffQuartilesPlotData$variable)
firstDiffQuartilesPlotData$subset <- factor(firstDiffQuartilesPlotData$subset, levels = c("Full (OLS)",
"Full (WLS)",
"Participants w>0.1\n(List-wise deletion OLS)",
"Factually correct\n(List-wise deletion OLS)"))
###############
# save ME plot
pdf("figures/marginalFDshift(Kanegreyscale).pdf", width=11, height=7)
ggplot(firstDiffQuartilesPlotData[firstDiffQuartilesPlotData$subset!="Participants w>0.1\n(List-wise deletion OLS)",]) +
#theme_classic() +# coord_flip()+
theme_pubr() +
# geom_pointrange(aes(x=variable, y = FDmean, ymin = FDlow90, ymax = FDhigh90, colour=subset),
#                position = position_dodge(width =.75), size=1.5)+
geom_pointrange(aes(x=variable, y = FDmean, ymin = FDlow95, ymax = FDhigh95, colour=subset, shape=subset),
position = position_dodge(width =.75), size=1.5)+
scale_shape_manual(values = c(17,18,19, 16))+
geom_hline(aes(yintercept= 0), linetype="dashed", size=.5, colour="black") +
facet_wrap(~model, ncol=3) + scale_colour_grey(start = 0, end = 0.7)+
theme(axis.title=element_text(size=20), axis.text = element_text(size=18), legend.text=element_text(size=18),
strip.text = element_text(size=20), strip.background = element_rect(fill = NA, color = "black"),
legend.position="bottom", legend.title = element_text(size=20),
title = element_text(size=25),  legend.background = element_blank(),
legend.box.background = element_rect(colour = "black"), axis.text.x = element_text(angle = 45, hjust = 1),
panel.border = element_blank(),
panel.background = element_rect(fill = NA, color = "black"),
panel.grid = element_blank()
#  strip.background = element_blank(),
# strip.text.x = element_blank()
) +
geom_vline(xintercept = c(1.5,2.5)) +
labs(y='\nMarginal Effect of Treatment\n', x='\nTreatment\n', colour="Sample\n(Model):", shape="Sample\n(Model):")
dev.off()
# process text, in this case processing two languages
# separately (Spanish and Brazilian Portuguese)
processedKane <- textProcessor(kaneData$newsFMC, metadata = kaneData, language = "en")
# prep document for both languages
outKane <- prepDocuments(processedES$documents, processedES$vocab, processedES$meta)
# prep document for both languages
outKane <- prepDocuments(processedKane$documents, processedKane$vocab, processedKane$meta)
stmES <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
data = outKane$meta, init.type = "Spectral")
# execute STMs using variables that may be associated w/ information retention
# in this instance, I include age, if respondents viewed their most preferred issue, and gender
set.seed(12345)
outKane <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
data = outKane$meta, init.type = "Spectral")
# show the words most associated w/ each topic
labelTopics(outKane, c(1:3))
plot.topicCorr(topicCorr(outKane))
# check words that are associated w/ one topic
checkBeta(stmES, tolerance = 0.01); checkBeta(stmPT_BR, tolerance = 0.01)
# check words that are associated w/ one topic
checkBeta(outKane, tolerance = 0.01)
outKane <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
prevalence = ~ newsFMC, data = outKane$meta, init.type = "Spectral")
# process text, in this case processing two languages
# separately (Spanish and Brazilian Portuguese)
processedKane <- textProcessor(kaneData$newsFMC, metadata = kaneData, language = "en")
# prep document for both languages
outKane <- prepDocuments(processedKane$documents, processedKane$vocab, processedKane$meta)
# execute STMs using variables that may be associated w/ information retention
# in this instance, I include age, if respondents viewed their most preferred issue, and gender
set.seed(12345)
outKane <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
prevalence = ~ newsFMC, data = outKane$meta, init.type = "Spectral")
stmKane <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
prevalence = ~ newsFMC, data = outKane$meta, init.type = "Spectral")
# process text, in this case processing two languages
# separately (Spanish and Brazilian Portuguese)
processedKane <- textProcessor(kaneData$newsFMC, metadata = kaneData, language = "en")
# prep document for both languages
outKane <- prepDocuments(processedKane$documents, processedKane$vocab, processedKane$meta)
stmKane <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
prevalence = ~newsFMC, data = outKane$meta, init.type = "Spectral")
View(outKane)
stmKane <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
prevalence = ~NewsStoryConditions, data = outKane$meta, init.type = "Spectral")
# process text, in this case processing two languages
# separately (Spanish and Brazilian Portuguese)
processedKane <- textProcessor(kaneData$newsFMC, metadata = kaneData, language = "en")
# prep document for both languages
outKane <- prepDocuments(processedKane$documents, processedKane$vocab, processedKane$meta)
# execute STMs using variables that may be associated w/ information retention
# in this instance, I include age, if respondents viewed their most preferred issue, and gender
set.seed(12345)
stmKane <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
prevalence = ~NewsStoryConditions, data = outKane$meta, init.type = "Spectral")
# show the words most associated w/ each topic
labelTopics(outKane, c(1:3))
# show the words most associated w/ each topic
labelTopics(stmKane, c(1:3))
# check words that are associated w/ one topic
checkBeta(stmKane, tolerance = 0.01)
plot.topicCorr(topicCorr(stmKane))
stmKane$meta$NewsStoryConditions <- as.factor(stmKane$meta$NewsStoryConditions)
prepKane <- estimateEffect(1:3 ~ NewsStoryConditions, stmKane, meta = outKane$meta, uncertainty = "Global")
kaneData$NewsStoryConditions
kaneData$textViewed <- ifelse(kaneData$NewsStoryConditions=="Control", controlPromptES,
ifelse(kaneData$NewsStoryConditions=="Alienate", disunitedPrompt, unitedPrompt))
kaneData$textViewed <- ifelse(kaneData$NewsStoryConditions=="Control", controlPrompt,
ifelse(kaneData$NewsStoryConditions=="Alienate", disunitedPrompt, unitedPrompt))
controlPrompt <- c("Basic biographical information about President Trump")
unitedPrompt <- c("Trump recently pleasing many of his conservative supporters")
disunitedPrompt <- c("Trump recently upsetting many of his conservative supporters")
kaneData$textViewed <- ifelse(kaneData$NewsStoryConditions=="Control", controlPrompt,
ifelse(kaneData$NewsStoryConditions=="Alienate", disunitedPrompt, unitedPrompt))
# process text, in this case processing two languages
# separately (Spanish and Brazilian Portuguese)
processedKane <- textProcessor(kaneData$newsFMC, metadata = kaneData, language = "en")
# prep document for both languages
outKane <- prepDocuments(processedKane$documents, processedKane$vocab, processedKane$meta)
# execute STMs using variables that may be associated w/ information retention
# in this instance, I include age, if respondents viewed their most preferred issue, and gender
set.seed(12345)
stmKane <- stm(documents = outKane$documents, vocab = outKane$vocab, K = 3, max.em.its = 500,
prevalence = ~NewsStoryConditions, data = outKane$meta, init.type = "Spectral")
# show the words most associated w/ each topic
labelTopics(stmKane, c(1:3))
plot.topicCorr(topicCorr(stmKane))
# check words that are associated w/ one topic
checkBeta(stmKane, tolerance = 0.01)
stmKane$meta$NewsStoryConditions <- as.factor(stmKane$meta$NewsStoryConditions)
prepKane <- estimateEffect(1:3 ~ NewsStoryConditions, stmKane, meta = outKane$meta, uncertainty = "Global")
# create function to:
# (1) get overall distribution of topics
# (2) get simulated estimates (draws from the posterior distribution)
# of each topic from each document
# (3) determine if respondent correctly identified/recalled
# which topic they viewed as part of the textual framing treatment
# User provides:
# STM model that has been estimated
# nsims = 1000 default
#
drawsFunc <- function(stmModel=NULL, Nsims=1000, stmDocs=NULL, stmMeta=NULL){
drawsDataFrame <- thetaPosterior(stmModel, nsims = 1000, type="Local", documents=stmDocs)
drawsDataFrame <- t(as.data.frame(lapply(drawsDataFrame, colMeans)))
drawsDataFrame <- as.data.frame(drawsDataFrame)
browser()
rownames(drawsDataFrame) <- c(); names(drawsDataFrame) <- c('Control', 'United', 'Disunited')
drawsDataFrame$topicViewed <- stmMeta
drawsDataFrame$topicInterpretation <- colnames(drawsDataFrame)[apply(drawsDataFrame, 1, which.max)]
return(drawsDataFrame)
}
drawsKane <- drawsFunc(stmModel=stmKane, Nsims=1000, stmDocs=outKane$documents, stmMeta=outKane$meta$topicViewed)
names(drawsDataFrame)
rownames(drawsDataFrame)
View(drawsDataFrame)
rownames(drawsDataFrame) <- c()
View(drawsDataFrame)
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# set working directory
setwd('~/Documents/GitHub/CompLegFall2019/data/NoticePapers_HTML/')
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo"), pkgTest)
######################
# set working directory
# load data
# and load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
basic.packages <- c("package:stats","package:graphics","package:grDevices","package:utils","package:datasets","package:methods","package:base")
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
package.list <- setdiff(package.list,basic.packages)
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
detachAllPackages()
# set working directory
setwd('~/Documents/GitHub/CompLegFall2019/data/NoticePapers_HTML/')
# load libraries
pkgTest <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
lapply(c("stringr", "dplyr", "plyr", "tidyverse", "rvest", "zoo"), pkgTest)
#################################
# function to parse HTML
#################################
# file names
files <- list.files(pattern="*.html", full.names=TRUE, recursive=FALSE)
files
# file names
files <- list.files(pattern="*.html", full.names=TRUE, recursive=FALSE)
files
?list.files
# file names
files <- list.files(pattern="*.html", full.names=TRUE, recursive=FALSE)
files
?alply
# parse XML
out <- alply(.data = files, .margins = 1, .fun = parse_HTML, .progress = "text", .inform = TRUE)
#################################
# function to parse HTML
#################################
parse_HTML <- function(file) {
# parliament
info <- str_split(file, "_|\\.")
info <- unlist(info)
# read in HTML
html <- read_html(file)
# heading
h <- html %>% html_nodes("b") %>% html_text()
sitting_date <- str_extract(h[6], "[A-Z][a-z]+, [A-Z][a-z]+ [0-9]{1,2}, [0-9]{4}")
# text
td <- html %>% html_nodes("td")
td_text <- td %>% html_text()
# footnote
sup <- td %>% html_node("b") %>% as.character()
sup <- as.numeric(str_detect(sup, "sup>2<"))
# class
class <- td %>% html_attr("class")
# headings
h3 <- td %>% html_node("h3") %>% html_text()
h4 <- td %>% html_node("h4") %>% html_text()
h4[h3 == "Private Members' Business"] <- "Private Members' Business"
# paragraph
p <- td %>% html_node("p") %>% html_text()
# text
td <- td %>% html_text()
# check number of questions
if(length(td) == 0) {
return(NULL)
}
# make a data frame
out <- data.frame(key_ID = 1:length(td),
parliament_number = info[3],
session_number = info[4],
chamber_number = 1,
sitting_number = info[5],
sitting_date = sitting_date,
heading = h4,
class = class,
footnote = sup,
text = td,
paragraph = p,
stringsAsFactors = FALSE)
# return data frame
return(out)
}
##################################################
# read in data
##################################################
# file names
files <- list.files(pattern="*.html", full.names=TRUE, recursive=FALSE)
# parse XML
out <- alply(.data = files, .margins = 1, .fun = parse_HTML, .progress = "text", .inform = TRUE)
# stack data frames
View(out)
# stack data frames
out <- do.call("rbind", out)
View(out)
View(out)
View(out)
parse_HTML <- function(file) {
# parliament
info <- str_split(file, "_|\\.")
info <- unlist(info)
# read in HTML
html <- read_html(file)
browser()
# heading
h <- html %>% html_nodes("b") %>% html_text()
sitting_date <- str_extract(h[6], "[A-Z][a-z]+, [A-Z][a-z]+ [0-9]{1,2}, [0-9]{4}")
# text
td <- html %>% html_nodes("td")
td_text <- td %>% html_text()
# footnote
sup <- td %>% html_node("b") %>% as.character()
sup <- as.numeric(str_detect(sup, "sup>2<"))
# class
class <- td %>% html_attr("class")
# headings
h3 <- td %>% html_node("h3") %>% html_text()
h4 <- td %>% html_node("h4") %>% html_text()
h4[h3 == "Private Members' Business"] <- "Private Members' Business"
# paragraph
p <- td %>% html_node("p") %>% html_text()
# text
td <- td %>% html_text()
# check number of questions
if(length(td) == 0) {
return(NULL)
}
# make a data frame
out <- data.frame(key_ID = 1:length(td),
parliament_number = info[3],
session_number = info[4],
chamber_number = 1,
sitting_number = info[5],
sitting_date = sitting_date,
heading = h4,
class = class,
footnote = sup,
text = td,
paragraph = p,
stringsAsFactors = FALSE)
# return data frame
return(out)
}
# file names
files <- list.files(pattern="*.html", full.names=TRUE, recursive=FALSE)
# parse XML
out <- alply(.data = files, .margins = 1, .fun = parse_HTML, .progress = "text", .inform = TRUE)
# parliament
info <- str_split(file, "_|\\.")
View(info)
# read in HTML
html <- read_html(file)
# parse XML
out <- alply(.data = files, .margins = 1, .fun = parse_HTML, .progress = "text", .inform = TRUE)
# heading
h <- html %>% html_nodes("b") %>% html_text()
?html_nodes
