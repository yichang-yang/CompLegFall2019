# libraries
library(stringr)
library(tidyverse)
# clear workspace
rm(list = ls())
# clear console
cat("\014")
# parameters
parliament <- 41
session <- 2
sittings <- 235
# start progress bar
pb <- txtProgressBar(min = 2, max = sittings, style = 1)
# loop through sittings
for(i in 1:sittings) {
browser()
# set working directory
setwd("~/Dropbox/Professional/Projects/Parliaments Project/Canada/Table of Contents (HTML)/")
# make URL
url <- str_c("https://www.ourcommons.ca/DocumentViewer/en/", parliament, "-", session, "/house/sitting-", i, "/order-notice/page-ToC", collapse = "")
# make file name
file <- str_c("table_of_contents_", parliament, "_", session, "_", i, ".html", collapse = "")
# download file
download.file(url, file, quiet = TRUE)
# random delay
Sys.sleep(runif(1, 0, 0.25))
# update progress bar
setTxtProgressBar(pb, i)
}
str_c("https://www.ourcommons.ca/DocumentViewer/en/", parliament, "-", session, "/house/sitting-", i, "/order-notice/page-ToC", collapse = "")
# libraries
library(stringr)
library(tidyverse)
# clear workspace
rm(list = ls())
# clear console
cat("\014")
# parameters
parliament <- 42
session <- 1
# libraries
library(stringr)
library(tidyverse)
# clear workspace
rm(list = ls())
# clear console
cat("\014")
# parameters
parliament <- 42
session <- 1
sittings <- 438
# start progress bar
pb <- txtProgressBar(min = 2, max = sittings, style = 1)
# loop through sittings
for(i in 1:sittings) {
browser()
# set working directory
setwd("~/Documents/GitHub/compLegFall2019/data/canadaTextParsing/Questions/")
# make URL
url <- str_c("https://www.ourcommons.ca/DocumentViewer/en/", parliament, "-", session, "/house/sitting-", i, "/order-notice/page-ToC", collapse = "")
# make file name
file <- str_c("table_of_contents_", parliament, "_", session, "_", i, ".html", collapse = "")
# download file
download.file(url, file, quiet = TRUE)
# random delay
Sys.sleep(runif(1, 0, 0.25))
# update progress bar
setTxtProgressBar(pb, i)
}
â„¢Q
Q
# libraries
library(stringr)
library(tidyverse)
# clear workspace
rm(list = ls())
# clear console
cat("\014")
# parameters
parliament <- 42
session <- 1
sittings <- 438
##################################################
# table of contents
##################################################
# start progress bar
pb <- txtProgressBar(min = 2, max = sittings, style = 1)
# loop through sittings
for(i in 1:sittings) {
browser()
# set working directory
setwd("~/Documents/GitHub/compLegFall2019/data/canadaTextParsing/Questions/")
# make URL
url <- str_c("https://www.ourcommons.ca/DocumentViewer/en/", parliament, "-", session, "/house/sitting-", i, "/order-notice/page-ToC", collapse = "")
# make file name
file <- str_c("table_of_contents_", parliament, "_", session, "_", i, ".html", collapse = "")
# download file
download.file(url, file, quiet = TRUE)
# random delay
Sys.sleep(runif(1, 0, 0.25))
# update progress bar
setTxtProgressBar(pb, i)
}
# set working directory
setwd("~/Documents/GitHub/compLegFall2019/data/canadaTextParsing/Questions/")
# make URL
url <- str_c("https://www.ourcommons.ca/DocumentViewer/en/", parliament, "-", session, "/house/sitting-", i, "/order-notice/page-ToC", collapse = "")
url
# start progress bar
pb <- txtProgressBar(min = 2, max = sittings, style = 1)
# loop through sittings
for(i in 1:sittings) {
#browser()
# set working directory
setwd("~/Documents/GitHub/compLegFall2019/data/canadaTextParsing/Questions/")
# make URL
url <- str_c("https://www.ourcommons.ca/DocumentViewer/en/", parliament, "-", session, "/house/sitting-", i, "/order-notice/page-ToC", collapse = "")
# make file name
file <- str_c("table_of_contents_", parliament, "_", session, "_", i, ".html", collapse = "")
# download file
download.file(url, file, quiet = TRUE)
# random delay
Sys.sleep(runif(1, 0, 0.25))
# update progress bar
setTxtProgressBar(pb, i)
}
?tryCatch
# loop through sittings
for(i in 1:sittings) {
#browser()
# set working directory
setwd("~/Documents/GitHub/compLegFall2019/data/canadaTextParsing/Questions/")
# make URL
url <- str_c("https://www.ourcommons.ca/DocumentViewer/en/", parliament, "-", session, "/house/sitting-", i, "/order-notice/page-ToC", collapse = "")
# make file name
file <- str_c("table_of_contents_", parliament, "_", session, "_", i, ".html", collapse = "")
tryCatch(
# download file
download.file(url, file, quiet = TRUE),
finally = print("NA")
)
# random delay
Sys.sleep(runif(1, 0, 0.25))
# update progress bar
setTxtProgressBar(pb, i)
}
url.exists(url)
library(RCurl)
url.exists(url)
url.exists(url)
url.exists(url)
try(url.exists(url)
)
url_exists <- function(x, non_2xx_return_value = FALSE, quiet = FALSE,...) {
suppressPackageStartupMessages({
require("httr", quietly = FALSE, warn.conflicts = FALSE)
})
# you don't need thse two functions if you're alread using `purrr`
# but `purrr` is a heavyweight compiled pacakge that introduces
# many other "tidyverse" dependencies and this doesnt.
capture_error <- function(code, otherwise = NULL, quiet = TRUE) {
tryCatch(
list(result = code, error = NULL),
error = function(e) {
if (!quiet)
message("Error: ", e$message)
list(result = otherwise, error = e)
},
interrupt = function(e) {
stop("Terminated by user", call. = FALSE)
}
)
}
safely <- function(.f, otherwise = NULL, quiet = TRUE) {
function(...) capture_error(.f(...), otherwise, quiet)
}
sHEAD <- safely(httr::HEAD)
sGET <- safely(httr::GET)
# Try HEAD first since it's lightweight
res <- sHEAD(x, ...)
if (is.null(res$result) ||
((httr::status_code(res$result) %/% 200) != 1)) {
res <- sGET(x, ...)
if (is.null(res$result)) return(NA) # or whatever you want to return on "hard" errors
if (((httr::status_code(res$result) %/% 200) != 1)) {
if (!quiet) warning(sprintf("Requests for [%s] responded but without an HTTP status code in the 200-299 range", x))
return(non_2xx_return_value)
}
return(TRUE)
} else {
return(TRUE)
}
}
url_exists(url)
url_exists(url)[1]
