df$party_name[df$party_name == "Conservative"] <- "Conservative Party of Canada"
df$party_name[df$party_name == "Liberal"] <- "Liberal Party of Canada"
df$party_name[df$party_name == "NDP"] <- "New Democratic Party"
df$party_name[df$party_name == "Green Party"] <- "Green Party of Canada"
# fix constituency name
df$constituency_name[df$constituency_name == "Western Arctic"] <- "Northwest Territories"
# drop title
df$title <- NULL
# chamber name
df$chamber_name <- "House of Commons"
# full name
df$full_name <- str_c(df$first_name, df$last_name, sep = " ")
# drop those observations missing first names
df <-  filter(df, first_name != "")
return(df)
}
allMPs <- cleanDates(allMPs, "start_date", "end_date")
View(allMPs)
# INPUT:
# (1) data frame that dates are in
# (2) name of column with start dates (start_date)
# (3) name of column with end dates (end_date)
# OUTPUT:
# start_year, start_month, start_day
# end_year, end_month, end_day
cleanDates <- function(df, start, end){
# remove timestamp from string
# removing leading "20" in some year dates
# converting all to prefered date object and format
browser()
df[,start] <- as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,start])), "%m/%d/%y")
df[,end] <- as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,end])), "%m/%d/%y")
# clean party names
df$party_name[df$party_name == "Conservative"] <- "Conservative Party of Canada"
df$party_name[df$party_name == "Liberal"] <- "Liberal Party of Canada"
df$party_name[df$party_name == "NDP"] <- "New Democratic Party"
df$party_name[df$party_name == "Green Party"] <- "Green Party of Canada"
# fix constituency name
df$constituency_name[df$constituency_name == "Western Arctic"] <- "Northwest Territories"
# drop title
df$title <- NULL
# chamber name
df$chamber_name <- "House of Commons"
# full name
df$full_name <- str_c(df$first_name, df$last_name, sep = " ")
# drop those observations missing first names
df <-  filter(df, first_name != "")
return(df)
}
allMPs <- cleanDates(allMPs, "start_date", "end_date")
df[,start]
sort(  df[,start])
rev(sort(  df[,start]))
gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,start]))
as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,start])), "%m/%d/%y")
gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,start]))
# INPUT:
# (1) data frame that dates are in
# (2) name of column with start dates (start_date)
# (3) name of column with end dates (end_date)
# OUTPUT:
# start_year, start_month, start_day
# end_year, end_month, end_day
cleanDates <- function(df, start, end){
# remove timestamp from string
# removing leading "20" in some year dates
# converting all to prefered date object and format
#browser()
df[,start] <- as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,start])), "%m/%d/%y")
df[,end] <- as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,end])), "%m/%d/%y")
# clean party names
df$party_name[df$party_name == "Conservative"] <- "Conservative Party of Canada"
df$party_name[df$party_name == "Liberal"] <- "Liberal Party of Canada"
df$party_name[df$party_name == "NDP"] <- "New Democratic Party"
df$party_name[df$party_name == "Green Party"] <- "Green Party of Canada"
# fix constituency name
df$constituency_name[df$constituency_name == "Western Arctic"] <- "Northwest Territories"
# drop title
df$title <- NULL
# chamber name
df$chamber_name <- "House of Commons"
# full name
df$full_name <- str_c(df$first_name, df$last_name, sep = " ")
# drop those observations missing first names
df <-  filter(df, first_name != "")
return(df)
}
allMPs <- cleanDates(allMPs, "start_date", "end_date")
View(allMPs)
######################
# set working directory
# load data
# and load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
# create list of basic libraries that are essential
basic.packages <- c("package:stats","package:graphics","package:grDevices",
"package:utils","package:datasets","package:methods","package:base")
# find all packages that are floating in the global environment
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
# make sure that basic packages aren't dropped
package.list <- setdiff(package.list,basic.packages)
# remove all extra packages
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
# execute function to keep only basic
# packages in global envir.
detachAllPackages()
# set working directory
# which should be the same for everyone
# assuming GitHub is in your "Documents" folder
setwd("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Members (CSV)/")
# load libraries
pkgTest <- function(pkg){
# check whether a package is installed
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
# if there are any packeages that need to be installed
if (length(new.pkg))
# install package
install.packages(new.pkg, dependencies = TRUE)
# and then load all packages user listed
sapply(pkg, require, character.only = TRUE)
}
# apply function to load libraries and install them if necessary
lapply(c("stringr", "plyr", "tidyverse", "tidyr", "dplyr"), pkgTest)
#######################
# load dataset of MPs
#######################
# read in your .csv files
# first, check which files are in the working directory
filenames <- gsub("\\.csv$","", list.files(pattern="\\.csv$"))
# iterate over those file names and read each .csv
for(i in filenames){
# Tip: you almost always want to read stringsAsFactors=F in .csv
# because you want to often text as text, not factors
assign(i, read.csv(paste(i, ".csv", sep=""), stringsAsFactors = F, encoding = "UTF-8"))
}
################################
# load dataset of constituencies
################################
# you'll want this later to merge w/ info from MPs
constituencies <- read.csv("../canada_constituencies.csv", stringsAsFactors = F, encoding = "UTF-8")
########################################
# distinguish b/w parliamentary sessions
########################################
# create a variable denoting which parliamentary session each dataframe is
# this is useful for when we combine the dataframes together by stacking
# them on top of each other by row (see line 89)
# first, create function to go over each dataframe
findNumber <- function(df){
# and grab any numbers in the name of that dataframe
# create that variable and apply value for each row
df$parliamentNumber <- gsub("[^[:digit:].]", "", i)
# return data frame
return(df)
}
# find all data frames in the global environment
globalEnvir <- .GlobalEnv
# iterate over all those data frame
for(i in filenames){
# apply function to each data frame in global environment
globalEnvir[[i]] <- findNumber(globalEnvir[[i]])
}
# can always check to make sure it worked
# ex; look at canada_commons_members_parl40$parliamentNumber
#############################
# create one large dataframe
#############################
# stack dataframes on top of each other
# to create one large dataframe
allMPs <- do.call(rbind, mget(filenames))
###################################
### clean names, dates, and parties
###################################
# rename variables to match codebook
names(allMPs) <- c("title", "first_name", "last_name", "constituency_name",
"province_name", "party_name", "start_date", "end_date", "parliament_number")
# INPUT:
# (1) data frame that dates are in
# (2) name of column with start dates (start_date)
# (3) name of column with end dates (end_date)
# OUTPUT:
# start_year, start_month, start_day
# end_year, end_month, end_day
cleanDates <- function(df, start, end){
# remove timestamp from string
# removing leading "20" in some year dates
# converting all to prefered date object and format
#browser()
df[,start] <- as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,start])), "%m/%d/%y")
df[,end] <- as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,end])), "%m/%d/%y")
# clean party names
df$party_name[df$party_name == "Conservative"] <- "Conservative Party of Canada"
df$party_name[df$party_name == "Liberal"] <- "Liberal Party of Canada"
df$party_name[df$party_name == "NDP"] <- "New Democratic Party"
df$party_name[df$party_name == "Green Party"] <- "Green Party of Canada"
# fix constituency name
df$constituency_name[df$constituency_name == "Western Arctic"] <- "Northwest Territories"
# drop title
df$title <- NULL
# chamber name
df$chamber_name <- "House of Commons"
# full name
df$full_name <- str_c(df$first_name, df$last_name, sep = " ")
# drop those observations missing first names
df <-  filter(df, first_name != "")
return(df)
}
allMPs <- cleanDates(allMPs, "start_date", "end_date")
View(allMPs)
View(canada_commons_members_parl42)
View(canada_commons_members_parl42)
unique(canada_commons_members_parl42$Constituency)
sort(unique(canada_commons_members_parl42$Constituency))
sort(unique(canada_commons_members_parl39$Constituency))
######################
# set working directory
# load data
# and load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
# create list of basic libraries that are essential
basic.packages <- c("package:stats","package:graphics","package:grDevices",
"package:utils","package:datasets","package:methods","package:base")
# find all packages that are floating in the global environment
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
# make sure that basic packages aren't dropped
package.list <- setdiff(package.list,basic.packages)
# remove all extra packages
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
# execute function to keep only basic
# packages in global envir.
detachAllPackages()
# set working directory
# which should be the same for everyone
# assuming GitHub is in your "Documents" folder
setwd("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Members (CSV)/")
# load libraries
pkgTest <- function(pkg){
# check whether a package is installed
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
# if there are any packeages that need to be installed
if (length(new.pkg))
# install package
install.packages(new.pkg, dependencies = TRUE)
# and then load all packages user listed
sapply(pkg, require, character.only = TRUE)
}
# apply function to load libraries and install them if necessary
lapply(c("stringr", "plyr", "tidyverse", "tidyr", "dplyr"), pkgTest)
#######################
# load dataset of MPs
#######################
# read in your .csv files
# first, check which files are in the working directory
filenames <- gsub("\\.csv$","", list.files(pattern="\\.csv$"))
# iterate over those file names and read each .csv
for(i in filenames){
# Tip: you almost always want to read stringsAsFactors=F in .csv
# because you want to often text as text, not factors
assign(i, read.csv(paste(i, ".csv", sep=""), stringsAsFactors = F, encoding = "UTF-8"))
}
View(canada_commons_members_parl42)
View(canada_commons_members_parl41)
#######################
# set working directory
# load data
# and load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
# create list of basic libraries that are essential
basic.packages <- c("package:stats","package:graphics","package:grDevices",
"package:utils","package:datasets","package:methods","package:base")
# find all packages that are floating in the global environment
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
# make sure that basic packages aren't dropped
package.list <- setdiff(package.list,basic.packages)
# remove all extra packages
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
# execute function to keep only basic
# packages in global envir.
detachAllPackages()
# set working directory
# which should be the same for everyone
# assuming GitHub is in your "Documents" folder
setwd("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Members (CSV)/")
# load libraries
pkgTest <- function(pkg){
# check whether a package is installed
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
# if there are any packeages that need to be installed
if (length(new.pkg))
# install package
install.packages(new.pkg, dependencies = TRUE)
# and then load all packages user listed
sapply(pkg, require, character.only = TRUE)
}
# apply function to load libraries and install them if necessary
lapply(c("stringr", "plyr", "tidyverse", "tidyr", "dplyr"), pkgTest)
#######################
# load dataset of MPs
#######################
# read in your .csv files
# first, check which files are in the working directory
filenames <- gsub("\\.csv$","", list.files(pattern="\\.csv$"))
# iterate over those file names and read each .csv
for(i in filenames){
# Tip: you almost always want to read stringsAsFactors=F in .csv
# because you want to often text as text, not factors
assign(i, read.csv(paste(i, ".csv", sep=""), stringsAsFactors = F, encoding = "UTF-16"))
}
################################
View(canada_commons_members_parl42)
# read in your .csv files
# first, check which files are in the working directory
filenames <- gsub("\\.csv$","", list.files(pattern="\\.csv$"))
# iterate over those file names and read each .csv
for(i in filenames){
# Tip: you almost always want to read stringsAsFactors=F in .csv
# because you want to often text as text, not factors
assign(i, read.csv(paste(i, ".csv", sep=""), stringsAsFactors = F, encoding = "UTF-8"))
}
View(canada_commons_members_parl42)
#######################
# set working directory
# load data
# and load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
# create list of basic libraries that are essential
basic.packages <- c("package:stats","package:graphics","package:grDevices",
"package:utils","package:datasets","package:methods","package:base")
# find all packages that are floating in the global environment
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
# make sure that basic packages aren't dropped
package.list <- setdiff(package.list,basic.packages)
# remove all extra packages
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
# execute function to keep only basic
# packages in global envir.
detachAllPackages()
# set working directory
# which should be the same for everyone
# assuming GitHub is in your "Documents" folder
setwd("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Members (CSV)/")
# load libraries
pkgTest <- function(pkg){
# check whether a package is installed
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
# if there are any packeages that need to be installed
if (length(new.pkg))
# install package
install.packages(new.pkg, dependencies = TRUE)
# and then load all packages user listed
sapply(pkg, require, character.only = TRUE)
}
# apply function to load libraries and install them if necessary
lapply(c("stringr", "plyr", "tidyverse", "tidyr", "dplyr"), pkgTest)
#######################
# load dataset of MPs
#######################
# read in your .csv files
# first, check which files are in the working directory
filenames <- gsub("\\.csv$","", list.files(pattern="\\.csv$"))
# iterate over those file names and read each .csv
for(i in filenames){
# Tip: you almost always want to read stringsAsFactors=F in .csv
# because you want to often text as text, not factors
assign(i, read.csv(paste(i, ".csv", sep=""), stringsAsFactors = F, encoding = "UTF-8"))
}
################################
# load dataset of constituencies
################################
# you'll want this later to merge w/ info from MPs
constituencies <- read.csv("../canada_constituencies.csv", stringsAsFactors = F, encoding = "UTF-8")
########################################
# distinguish b/w parliamentary sessions
########################################
# create a variable denoting which parliamentary session each dataframe is
# this is useful for when we combine the dataframes together by stacking
# them on top of each other by row (see line 89)
# first, create function to go over each dataframe
findNumber <- function(df){
# and grab any numbers in the name of that dataframe
# create that variable and apply value for each row
df$parliamentNumber <- gsub("[^[:digit:].]", "", i)
# return data frame
return(df)
}
# find all data frames in the global environment
globalEnvir <- .GlobalEnv
# iterate over all those data frame
for(i in filenames){
# apply function to each data frame in global environment
globalEnvir[[i]] <- findNumber(globalEnvir[[i]])
}
# can always check to make sure it worked
# ex; look at canada_commons_members_parl40$parliamentNumber
#############################
# create one large dataframe
#############################
# stack dataframes on top of each other
# to create one large dataframe
allMPs <- do.call(rbind, mget(filenames))
###################################
### clean names, dates, and parties
###################################
# rename variables to match codebook
names(allMPs) <- c("title", "first_name", "last_name", "constituency_name",
"province_name", "party_name", "start_date", "end_date", "parliament_number")
# INPUT:
# (1) data frame that dates are in
# (2) name of column with start dates (start_date)
# (3) name of column with end dates (end_date)
# OUTPUT:
# start_year, start_month, start_day
# end_year, end_month, end_day
cleanDates <- function(df, start, end){
# remove timestamp from string
# removing leading "20" in some year dates
# converting all to prefered date object and format
#browser()
df[,start] <- as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,start])), "%m/%d/%y")
df[,end] <- as.Date(gsub('20', '' , gsub('([0-9]+) .*', '\\1', df[,end])), "%m/%d/%y")
# clean party names
df$party_name[df$party_name == "Conservative"] <- "Conservative Party of Canada"
df$party_name[df$party_name == "Liberal"] <- "Liberal Party of Canada"
df$party_name[df$party_name == "NDP"] <- "New Democratic Party"
df$party_name[df$party_name == "Green Party"] <- "Green Party of Canada"
# fix constituency name
df$constituency_name[df$constituency_name == "Western Arctic"] <- "Northwest Territories"
# drop title
df$title <- NULL
# chamber name
df$chamber_name <- "House of Commons"
# full name
df$full_name <- str_c(df$first_name, df$last_name, sep = " ")
# drop those observations missing first names
df <-  filter(df, first_name != "")
return(df)
}
allMPs <- cleanDates(allMPs, "start_date", "end_date")
#############
# set working directory
# load data
# and load libraries
#######################
# remove objects
rm(list=ls())
# detach all libraries
detachAllPackages <- function() {
# create list of basic libraries that are essential
basic.packages <- c("package:stats","package:graphics","package:grDevices",
"package:utils","package:datasets","package:methods","package:base")
# find all packages that are floating in the global environment
package.list <- search()[ifelse(unlist(gregexpr("package:",search()))==1,TRUE,FALSE)]
# make sure that basic packages aren't dropped
package.list <- setdiff(package.list,basic.packages)
# remove all extra packages
if (length(package.list)>0)  for (package in package.list) detach(package, character.only=TRUE)
}
# execute function to keep only basic
# packages in global envir.
detachAllPackages()
# set working directory
# which should be the same for everyone
# assuming GitHub is in your "Documents" folder
setwd("~/Documents/GitHub/CompLegFall2019/data/canadaTextParsing/Members (CSV)/")
# load libraries
pkgTest <- function(pkg){
# check whether a package is installed
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
# if there are any packeages that need to be installed
if (length(new.pkg))
# install package
install.packages(new.pkg, dependencies = TRUE)
# and then load all packages user listed
sapply(pkg, require, character.only = TRUE)
}
# apply function to load libraries and install them if necessary
lapply(c("stringr", "plyr", "tidyverse", "tidyr", "dplyr"), pkgTest)
#######################
# load dataset of MPs
#######################
# read in your .csv files
# first, check which files are in the working directory
filenames <- gsub("\\.csv$","", list.files(pattern="\\.csv$"))
# iterate over those file names and read each .csv
for(i in filenames){
# Tip: you almost always want to read stringsAsFactors=F in .csv
# because you want to often text as text, not factors
assign(i, read.csv(paste(i, ".csv", sep=""), stringsAsFactors = F, encoding = "UTF-8"))
}
constituencies <- read.csv("../canada_constituencies.csv", stringsAsFactors = F, encoding = "UTF-8")
View(export)
unique(canada_commons_members_parl42$Constituency)
length(unique(canada_commons_members_parl42$Constituency))
